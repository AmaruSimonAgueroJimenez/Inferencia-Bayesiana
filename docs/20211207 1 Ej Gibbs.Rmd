---
title: "Ejemplo Algoritmo de Gibbs"
output: 
---

Modelo Bayesiano:
yi ~ n(mu, sig^2), i=1,...,n
mu ~ n(mu0, sig0^2)
sig^2 IG(nu0, beta0)

```{r}
paquetes_necesarios <- c("mcmc", "rjags")

# Para cada paquete en la lista:
for (p in paquetes_necesarios) {
  # Verificar si está instalado
  if (!require(p, character.only = TRUE, quietly = TRUE)) {
    # Si no está instalado, se instala
    install.packages(p)
    # Luego se carga
    library(p, character.only = TRUE)
  } else {
    # Si ya está instalado, simplemente se carga
    library(p, character.only = TRUE)
  }
}
```

```{r}
update_mu = function(n, ybar, sig2, mu_0, sig2_0){
	sig2_1 = 1.0 / (n/sig2 + 1/sig2_0)
	mu_1 = sig2_1 * (n*ybar/sig2 + mu_0/sig2_0)
	rnorm(n=1, mean=mu_1, sd=sqrt(sig2_1))
}
```

```{r}
update_sig2 = function(n, y, mu, nu_0, beta_0){
	nu_1 = nu_0 + n/2.0
	sumsq = sum((y - mu)^2)
	beta_1 = beta_0 + sumsq/2.0
	out_gamma = rgamma(n=1, shape=nu_1, rate=beta_1)
	1.0/out_gamma
}
```

```{r}
gibbs = function(y, n_iter, init, prior){
  ybar = mean(y)
  n = length(y)
  
  mu_out = numeric(n_iter)
  sig2_out = numeric(n_iter)
  
  mu_now = init$mu
  
  for(i in 1:n_iter){
    sig2_now = update_sig2(n=n, y=y, mu=mu_now, nu_0=prior$nu_0, beta_0=prior$beta_0)
    mu_now = update_mu(n=n, ybar=ybar, sig2=sig2_now, mu=prior$mu_0, sig2_0=prior$sig2_0)
    sig2_out[i] = sig2_now
    mu_out[i] = mu_now
  }
  cbind(mu=mu_out, sig=sig2_out)
}
```

Datos  
```{r}
y = c(1.2, 1.4, -.5, .3, .9, 2.3, 1.0, .1, 1.3, 1.9)
ybar = mean(y)
n = length(y)
```

A priori  
```{r}
prior = list()
prior$mu_0 = 0.0
prior$sig2_0 = 0.1
prior$nu_0 = 1.0
prior$beta_0 = 1.0
```

Histograma  
```{r}
hist(y, freq = FALSE, xlim=c(-1,3))
curve(dnorm(x=x, mean = prior$mu_0, sd = sqrt(prior$sig2_0)), lty=2, add=TRUE)
points(y, rep(0,n), pch=1)
points(ybar, 0, pch=1)
```

Inicialización  
```{r}
init = list()
init$mu = 0
```

Correr el algoritmo
```{r}
set.seed(53)
post = gibbs(y=y, n_iter=1e3, init=init, prior=prior)
```

Gráficos  
No sé cuáles son las distribuciones a posteriori para mu y sigma, pero puedo simular de esa distribución y graficar las densidades.   
```{r}
library(coda)
plot(as.mcmc(post))
```
Los mixing son buenos para ambos parámetros. Los peaks de sigma son usuales en este tipo de modelos, no implican un mal mixing.  

Puedo ver el estimador de Bayes a través de la media y los quantiles de la distribución.  
```{r}
summary(as.mcmc(post))
```


